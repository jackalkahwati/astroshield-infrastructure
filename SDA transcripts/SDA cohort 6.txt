Speaker 1  00:00
Not only those things, but we are also a community that is centered on a shared vision for success in space conflict. So the the sheer number of people that are involved in this thing is is quite large. The we have many partners throughout industry, throughout the DOD, we have a lot of soft partnerships, and folks who are excited to see what we're doing, are excited to contribute their knowledge and advocacy, and it's all to drive the success of what you're doing and turn it into actual operator capabilities, right? So we have the accelerator program, which you're starting out now, if you're in cohort six, it's been going on for a while, and we've used that accelerator program to grow the industrial base for the SDA expert area, expertise area. So we've got, we were, think about 12 companies strong in the first cohort, and now we're somewhere between 80 and 100 with this cohort, so that is a huge boost. And once our cohort members are able to develop the technology and demonstrate it, that provides a good catalyst to move on to further funding opportunities with the lab, as well as opportunities with other customers and probably the most. So yesterday, we kicked off four tech transfer programs through space works or, sorry, the Air Force Office of Scientific Research. Hopefully some of you were able to join for those meetings and see what those companies were up to. So it's an exciting time. We've also been sponsors for a large number of SBIR programs over the last two years. So that's how the ops the Apollo accelerator, is accelerating your work and making it more viable and ready for DOD consumption. We also engage heavily with the ops community. So one week ago, we held our demo day, which is the end of cohort five, and showed off all the great work that you guys have done to folks from the ops community. So we have folks from us, Space Command, the National Space Space Defense center, and several others, along with folks from SSC, we hosted Lieutenant General shes who is the Space Forces Component Commander for US Space Command. So those are sort of the environment of the lab. We want to build a community of shared interest, and have that community of shared interest result in tools for our space warriors, our guardians in those space communities or operations communities. How do we do that? So we take, we've other folks in DOD have come up with a number of kill chains that we are highly interested in in the Space Force. So those kill chains are basically describing how to do a certain kind of conflict, or how to avoid a certain kind of conflict. So we take those series of events and decompose them into atomic level problems, and provide those problems and this problem statements that you've seen and are answering to on the website, and really, we keep those problem statements as a guiding star for everything that we do. Those are the key things that we're trying to enable our war fighters to be able to fight with. Okay, hopefully that gives a little bit more of an overview than maybe you had before. Here's a little bit more about who we are and where we're located. So really, in this map shows the United States. We have partners and cohort participants in, I think, four continents at this point. We have Australia, Italy, South Korea, Austria, Japan, and there may be a few more I'm forgetting. So we have a very wide distribution across the planet. I have regular meetings with folks in many time zones. It's very exciting, see. So here's the kill chain. More on the operational piece of it. So general, Saltzman directed that in one of his CSO notes that the theory of success with Space Force depends heavily on avoiding operational surprise. So we need to, of course, uncover any kind of ways of producing surprise in the space environment, and in that we can deny the first mover advantage, we can advocate for Responsible counter space campaigning. And yeah, so if you can't tell already, I'm a program manager and not a space operator, and that's okay. There are many we have a bunch of subject matter experts in the room with you right now and in our broader network who can help answer some of those questions. Probably foremost of those is major Sean Allen, who many of you know. And I'm sure there'll be questions about it. So I'll go ahead and tell you about him now. So he's got a sort of ongoing situation that is going to keep him out of the lab for this week, and probably another week or two, I'm not quite sure. So he will show up when he's ready. And I'm sure those of you who have engaged with him know him and are excited to see him back. We are all waiting for him come back and he will anyway. Okay, so kill chains responsible counter space campaigning. General Saltzman is giving us the high level strategy. General bootleg directed us to stand up this tap lab and get on top of leveraging commercial and small businesses to make that happen is in a fast way, and that's what we're here to do. Okay? So expectations, so we are providing you guys with a number of really awesome benefits and environments in which to build some amazing tools. In exchange, we ask that you abide by our expectations, so we have a user agreement that you all agree to, and you apply to join the lab. I highly recommend reviewing that periodically, participation in the cohort is at your own expense. We expect that you will address a certain specific SDA tap lab problem statement, to be part of the lab, work collaboratively with others, community, communicate, actively, accept guidance and feedback. So basically, just being a good citizen of the lab, we expect that, as much as is practical, that you would be in the lab at least two days a week, Tuesday, Wednesday, Thursday are recommended. And I know we have, you know, this is a sort of a whole, a residual from previous cohorts when we are a little bit smaller, and now that we have a very sort of global presence, I know this is difficult for some so if you're in the local area, we expect you to be in two days per week. Otherwise, participate and engage as much as you can online. We expect that you would proactively ensure the lab staff are aware of your work in progress, and you'll have many opportunities to share that. We expect that you will integrate and demonstrate your solution within systems. And we'll get into that a little bit more when we talk about who all there's art system that we put in. Okay? So we have a midpoint chalk progress check that'll be halfway through the cohort, and we'll be expecting you to answer some very fast questions about your progress on the technical level. And if we don't think that you're meeting the expectations, we will ask you to not join Demo Day. Okay, prioritize deployment, integration and automation over optimization. So we want to see a functional thing more than we want to see a pretty thing, if that makes sense. The other one I'll add in is, please keep business development inappropriate channels. We love small businesses, but we ask that you would, you know, read the room and make sure that you know when business development conversations are appropriate. And if you have any questions, please ask us, don't be afraid. All right, who are we? So over the last the course of the life of the tap lab, things have changed a little bit over time. We've grown and expanded, and as a result, we've had to add some folks. So for a long time, it was just major Sean Allen, and as we in the last cohort, we realized that Sean was doing the work with about five people, and so we started to grow the team. So I've come on as the program manager. And we've also got some program support from Roger al tabelli. Hopefully this cohort will be hiring a deputy pm who will help me and be in person on the ground there in Colorado Springs. And then on our technical staff, we've got our senior engineer is David kurtenbach, who you just met a few minutes ago. He works for aerospace. He's done a fantastic job. Thank you, David. And then we are losing our Dr Jonathan Jordan, unfortunately, however, congratulations to him. He has won a promotion to Colonel in the reserves and is moving on to another position, and from the bottom of my heart, I don't know if you're listening out there, J too, but thanks for everything you've done for the lab and for us, it's been really great having you. It's going to be tough shoes to fill. And we are replacing him, and we'll announce that once we have that replacement queued up for infrastructure. Our lead there is Dan from Bulik. Dan, if you could maybe stand up and raise your hand, and so everyone knows who you are. Hopefully, folks already know we've been with the lab for a while. Our educational coordinator is Melissa hills with VT arc. Melissa, if you're in the room, if you could go ahead and show yourself there. And then I'm also pleased to interns. Cohort. We've got three interns. So we've got a captain, Chris Colin Gilmore and Lieutenant Alex Yovanovitch, who are super coders. I've got them to update the website, and there they will be available for some other engineering projects as well. And then I'm also pleased to welcome our newest intern, Chris Mueller, who I'm not sure if he's there today, but I know he just started onboarding this week. So if you see Chris around, give him a warm welcome, and I'll make sure that we have him gainfully employed, all right, and my I can't go past this page without giving a big thank you to the Innovation Hub team at VT arc. Thanks so much for everything you do day to day, Chuck and Sam and Janelle, you're definitely part of the family, and I can't move off this without thanking you heartily. Okay, so that is everything I've got for the lab overview. I'm going to turn it back over to Dave kritenbach. I'm

Speaker 2  12:25
Thanks. Appreciate that we're looking at the slides to kind of go through some of the IFT launch stuff that Dr Perlis will be presenting here in just a second. So I just want to put stop a few things, or maybe mentioned up there, right? You also have kind of the decomposition of capabilities, and we'll go through this too at Boulder dark. So I do want to just offer one thing. There was a lot of organizations talked about there. So he is just one field command within Space Force. There's a whole lot to it. Did you have questions about that stuff? I'm happy to break that down and kind of give those presentations and slide decks and word choice we can go through. So please, again, there's confusion about that or interest to learn more. I'm happy to share

Unknown Speaker  13:01
it. Travis. Travis,

Unknown Speaker  13:03
can you stop sharing slides? If you go, sure

Unknown Speaker  13:06
thing. Thank you.

Speaker 2  13:09
We'll pull up the slides here and go ahead and get started. Dr froage,

Speaker 3  13:15
Thanks, David. Hey everyone. I'm Greg froge from the University of Colorado, Boulder center for national security initiatives, also the space building awareness research lead. I've been here since the inaugural cohort year and a half ago. Now, very excited to continue on in cohort six. So the starship, IFT launches have been a great exercise. We've demonstrated out in the past. I'll talk a little bit of vignettes of previous demos that we've done on our capabilities. Again, this is just the showcase. We'll talk about more of the subsystems later today, but this allows us to show that the subsystems, we're starting to bring them together, they're starting to be integrated or passing useful information, impactful information, along the kill chain to decompose these types of threats. Let's go into the

Unknown Speaker  14:03
next slide. Please. I'm not seeing the slides.

Unknown Speaker  14:07
Thank you. I'll start to share them. Applause.

Unknown Speaker  14:37
Coming through now let me know if they are not,

Unknown Speaker  14:40
they're there. Thanks. All right, thank you. All right,

Speaker 3  14:43
they're gonna start ship. I have t8 launch exercises coming up, possibly later this month, maybe next month. It's pending FAA mishap report, given what happened with a starship. I have t7 launch date is TBD, but it's hopefully going to happen during this cohort. So it'd be another great exercise to showcase our capability, and a known launch exercise again. Ultimately, we want to get to uncooperative unknown launch exercises that showcase all of the different subsystems of this, this one, this current launch, might focus on a smaller amount of the subsystems, unfortunately. But again, we're just trying to show that the Kafka messaging system is working, that we're automating the process. Let me go on to the next slide, please. So this was the starship IFT four launch last summer where we demonstrated a couple of capabilities. We started with left of launch information. Do we have a good launch window, the launch then do we have launch detection at t equals zero, so myself, and also GTC analytics, so seismic and goes, imagery, launch detection. Then we pass that down the chain. There was a T, le generated by IRT and a ASAP screening, even though we knew ahead of one ASAP threat. But let's just run that exercise anyways, and with our c2 system, by Lighthouse distributing that message, and I believe we posted it to the UDL, I'm not sure, but then we also did a re entry projection by bikepro that was about seven different capabilities that we were able to implement in this and this was done in the guess I call the legacy system now node red for our process flow. And again, now we're moving to a messaging bus system with our distributed micro services. We go on to the next slide. This is starship IFT six, which we did for the last cohort. This launch was in December, and we brought in more capabilities. Again, left to launch. We had Booz Allen Hamilton do social media chatter. Could we look at spikes before launch that could be indicators we have intel on that we predict a launch window, and again, using launch detection methods like weather imagery and seismic data, we were able to detect launch a couple of minutes after launch and distribute that information if we go on to the next slide. Also did an anti satellite screening again, and we did some further analysis of the re entry. I feel like I'm missing something in here, but I think the main thing at the moment is we've done a lot of left launch information. We've done a lot of launch detection, where I really would like to bring this as we go to starship eight, for this cohort, is bringing the sensors and see if we can get are able to maintain custody in that sub orbital flight. So if you have a sensor that you can possibly pick up launch over, say, Africa or Australia, or if we can get a nei image of that suborbital flight, I think that would demonstrate, again, further capabilities that are being integrated into this kill chain. But we want to continue to show improvement as we go through these demonstrations. On the bottom right again, that's the example of the node red flow, of how all this was integrated, how we passed that message payload along the kill chain. And now again, this is being replaced by that Kafka message bus, so we don't have to do it on one flow. We can just exchange the information and a Pub Sub method. Next slide please. Here's the decomposed kill chain for the starship IoT eight. Everything in green, I feel like we've demonstrated before. Everything in red, we have not demonstrated. There might be some errors on this. So if I've missed any company, please let me know so I can check that box in the green, especially the orange ones are unknown demonstration. So where I want to focus on updating this launch exercise is that left to launch commercial capability. I know planet federal is around this time we've had some issues with data or imaging locations inside the US. Think we can overcome that now for this launch, so we can exercise that left to launch preparation capability. And then the other part that I've already pointed out is that in flight stage, can we maintain custody at an unrestricted or commercial level. Again, that's the great thing about the tap lab. This is all unrestricted, distributable commercial information. It doesn't depend on any elevated system. So it can rapidly enhance our prototypes and demonstrate them. Next slide, please. The next steps, I'm going to start plant some planning needs again. We have about a month until the next launch. I'm going to try to do weekly cadence and try to get the relevant points and contacts. If you're interested in participating in this exercise, please let me know, or the SDA cap lab staff know, and we will try to get you involved in this demonstration. We have a spreadsheet I will distribute this information on the general rocket chat page. You have a spreadsheet that you can put in your name, point of contact, what you're going to be contributing to this exercise. I think the most important thing again, is, what's your status of copyright messaging. And another thing we're going to try to integrate that we haven't done so previously is traceability. So if we have detection, was detection cubed by left launch information was maintaining custody cube by that detection so we'll pass on the traceability of the exercise. What was the initial origin of this exercise, and how far did we maintain that custody through the traceability? Let's go to the next page, please, beyond starship. IFT eight, we're going to continue to implement and exercise our capabilities and in a collaborated, federated system while we're doing these plannings for IFT eight down the road, this should all be automated, that we don't have to get together, that the system will just exist like you continue to show that. Yep, we started with left launch all the way to on orbit. As we mature battle management system, think beyond also the sub orbital flight. Again, we're not fully utilizing a lot of the subsystems like CCDM. So we want to look at exercises that we can utilize those systems, like maybe RPO exercises as we prepare for the Victus Hayes mission coming up next year, in October. But we want to demonstrate on those types of missions as well. I think I have one more slide, right? So opportunities and outcome, besides participating in the lab, I think some of the opportunities that we want to bring with this exercise is at the end of the cohort. We can use this as an example, like we did for starship IoT six. You can use IFT eight again on cohort demo day to show how our capabilities were integrated to all the sponsors as they come here to show that this is a novel and pivotal system that adds resiliency and redundancy to systems that already exist out there. It's not a monolithic stove pipe system. It is a collaborative entity of industry, academics and government partnership. Second point is putting together a publication for the Amos tech conference. You are also interested in participating in that, please let me know. We have a month left to submit abstracts. I'm going to start generating an abstract again. This is a unique thing that we can bring to Amos. A lot of talks at Amos are look at what I did. I think this is a chance to say, look at what we did with multiple companies, academics and government partnerships. I think that's a pretty unique thing to bring so more people that we have on board, I think that makes it more novel. And again, this is a way for you as small business, big business academics say that you're a part of this and get your name up on the Amos stage. You're interested in that let me know. Lastly, we've released the related material on this before in the past with IFT four and IFT six, and will continue to do so as we demonstrate the enhancement of our capabilities. If you have any questions or know how I'm doing on time, either do we want to take questions now or just hold them to the end? I Yeah.

Speaker 2  24:28
Oh, thank you for the Amos paper. Those are great opportunities, kind of highlight what we do. If you're not been to Amos or not familiar with it, it is a very well attended and is in Hawaii, right? So everybody wants to go, but it's something that is a we could really stand out and kind of show the uniqueness of this lab and those types of things do great work for just kind of publicizing what we're doing and getting that message out to folks. Questions. Anyone for Greg?

Unknown Speaker  24:53
Thank you, Greg. Oh yeah. On the

Speaker 4  24:56
launch detection, I was wondering what is the roadmap for moving away from starship into looking

Unknown Speaker  25:01
at small rockets.

Speaker 3  25:04
Yeah, so that's something I've started to do, and I believe GTC is also starting to do. Of course, starship is an extremely bright rocket, which is great. So it was really easy to look at it, but we looked at some of the other Falcon launches, the Starliner launch from Ula, the Blue Origin launch vehicle as well. Working on some of the really small ones, like Rocket Lab out of New Zealand has been difficult, but that is a possible launch site, or the victor's case mission. So we are trying to stay on top of that, sweet.

Unknown Speaker  25:35
Let's do hard things.

Unknown Speaker  25:38
Any other questions?

Speaker 3  25:41
Thank you, Rick, Yep, I'll be around all day. So if you have any other questions.

Speaker 2  25:57
So you heard a lot about capabilities, you saw kind of the decomposition of the kill chain that's in there, all right? So just kind of set the stage this SD attack lab was initially stood up with this concept of apps to fill gaps, right? So how do we deliver capability and a rapid time, relevant timeline to ultimately, like, create capabilities as needed by the warfighter type of a thing? So that concept came down to modularized kind of development, right? Some of the node red stuff. And those of you been around, you know we were just doing, hey, company, a you develop, you make an API that someone can call that's going to be passed down the kill chain, and that day is going to be processed and passed down the kill chain until we have a solution at the end that can kind of do this full end to end. SDA space battle management type of thing. I'm using a lot of terms, if you're not familiar with again, you can have to happily break them down a little bit further for y'all. So as we were building that, right, we were, where do we interject these capabilities? Where's the need within the warfighter, that sort of thing? But we're always kind of in this struggle of what we were doing great and advanced things in developing there's also the business side of the house, right? Is that we need to be able to communicate what we're doing with relevant stakeholders or potential customers, and how do we kind of do that? So that's where welders are. Was eventually kind of came out of that concept, because mentioned as well too. So we'll break into battle, but you can go to the next slide, please. You go next slide as well. The welders are a comprehensive end to end space battle management tool. And this does a couple of things for us. First off, it demonstrates our capabilities as a lab. This is basically the tool that integrates what all of you are doing or will be doing in this next cohort into one cohesive application, essentially. So as I was talking about, hey, we're here to develop these apps to build needs within capabilities, right? There's programs of record that exist, that maybe need UCT processing or large launch detection or something like that, and we have those individual capabilities within you all. But we said we need a way to demonstrate this at a broader scale, to really show the true capability of it. And so we've looked at IFT launches to be kind of our known test graph, right? Your ground truth that you can kind of compare things to, we've been able to really demonstrate a lot of capabilities behind that. And so this is kind of an additional kind of effort that's doing that same thing. Victor Haze is an upcoming exercise that is looking at rapid response for space capabilities. It's ran by the space Safari office, and we are going to be supporting them through welders arc initiative with some of our space battle management capabilities, right? And so that was initially kind of really kicked off and really, like, let us a lot of motivations to develop it the long term. This is just a way for us to really eventually show what our capabilities are and how they can be delivered. So you can see up there, it's orchestrated into subsystems, the system of systems. Please don't look at the box and think that is associated or correlates to the importance or the size of it, right? Because there is a lot that's loaded in all these each one of these subsystems has a lead. So how we've kind of organized here in the lab is that we put your capabilities within one of these subsystems so that you have a lead to help kind of orchestrate and coordinate and get work moving in the right direction, so that we can all move towards this grand division of what welders arc is. I say all that to say some of you all will not align perfectly with some of these subsystems, and that's perfectly fine too, right? We still want to resolve SCA issues and deliver capabilities and functionality to warfighters that are needed. So as we get into these conversations, and you're looking at those, if you look at one of these, you think it's, I don't fit in any of them. Don't leave please. Just continue to have those conversations, and we'll find ways to make sure that you all are integrated into it. So we are going to go through. Maybe we should probably. Is there time for a break on the schedule at all? Okay, we can go through and start discussing some of the subsystems. Anyone want to bring each of the subsystem leads up here to be able to introduce what they're doing specifically, and as they're having these conversations, please try to identify where it is that you see yourself playing in and where it is that you can help out again. It's an open conversation, and I know things are going to evolve over time, so especially for those of you who are made, I mean, if you knew, or you're returning, right, you're going to come in here with an idea and a plan to develop over the next three months. I'm going to say one thing towards that is, don't necessarily get hung up on the three month thing. Don't think you have to do an end to end solution in three months. I mean, the true capability needs are going to be out there. Going to extend six, 912, months type of thing. Just look at what your progress is going to look like in the next right? So just do this incremental, kind of iterative process that you're going to do through it. So you'll see, as we look through some of this, right, where you're going to align, what type of capability do you have to provide, and it's going to change over time. It always does. You might have an idea of something you want to develop right now, and then you hear there's six other people. There's six other people doing it, you might say, maybe I'll visit a little bit. And that's anticipated. That happens all the time. So just keep an open mind as you have these conversations. Reach out to substance abuse with questions about it, and with that, do we have Tony? Is he on the line? Are we certain Alice's first we'll go to Al on subsystem Z.

Speaker 5  30:53
I'm Alex zero lead, which is basically the ingestion of all external data sources into the well desired infrastructure. The majority of that data tends to come from SDA sensors, but there is a variety of other data sources that we also make extensive use of. So the general guideline for data use within the Wellers arc ecosystem is a hub spoke methodology. You have two hubs that is both the UDL and then a Kafka broker that's run by the Wellers arch. The concept, or the desire, to use a HubSpot methodology, as opposed to direct connections such as REST APIs, is to allow a broader variety of data producers and data subscribers to be able to interface together using one common topic, or one common interface, as opposed to everyone having to set up individual REST APIs understand every single interconnection. So with that said, most of the SBA sensors are producing data to go to the UDL, and that's primarily because the UDL has existed for several years now, and has there's extensive desire to do so, a lot of that data can be sold to the JCO and other organizations around the world that also participate in the global data marketplace. So there's incentive if you're an SBA concern to provide your data in that ecosystem, but that's also why weather dark is pulling from it. Then we have a variety of other types of data, such as weather launch detections, launch upgrades of interest. Those don't fit neatly in the existing UDL topics. So we have stood up the well, there's our Kafka message bus to support that. This allows us also, since we control it, this allows us to quickly stand up new topics with specific schemas and message formats that are applicable to needs of voters arc across the board. The goal is to bring in data and make it available to all participants, even if, as a company you are, you have the capability to do some interesting algorithms and you have special things that you would like to do in other subsystems, there's a decent chance that if you're a potential data provider, you should also be working with me in substance zero just to provide that data To the rest of the cohorts, the data that is provided to the cohort participants is to only be used by the SBA cap lab cohort members to support this effort is not to be used for any other purposes. So if you are worried that your data is going to be used for anything outside of the lab is not supposed to be. So keep that in mind on both sides, the producer and the user of the data. As of today, we have, or very, very close to having data available from IRT cloud and digantara as electro optical observations in UDL. Queen Garcia is providing RF observations, and then both Turion and arco dynamics, very, very close to having their nei data available in UDL, as well as some information such as RSO characterization in the optimism that should be happening in a matter of a week or so. Then we have a variety of different launch detection providers, and I suspect I've left some off, but etc, provides seismic interface sounds, launch detections, and then CU Boulder, obviously providing overhead imaging with goes launch detections. There are several other companies that have that capability, but are not quite yet integrated into the optimistic list. We also have weather data, both terrestrial weather and space weather. Earthcast is currently publishing to the coffee message, bus, restaurant weather at a 15 minute cadence, and then both Orion and earthcast be providing neutral density for space weather. And there's more, I believe, but can certainly get to that. Something else. I want to make clear, even if you're not necessarily aware of what exactly your data might be used for, there's a good chance that, if you just advertise the existence of your data and that you're going to put it or make it available to promote participants, someone will find a use for it. I mean, even just last week, cohort participants have been working in the same room for months, found out about each other's data and realized, hey, actually weather data would be useful for seismic and infrasound. Infrasound specifically. So DTC is going to start making use of weather data just to update their or to have higher accuracy and for sound models. Are there any questions about data ingestion and utilization across the

Unknown Speaker  37:01
Yes?

Speaker 5  37:09
It's certainly possible, and there are always exceptions to the rule. There was a question as to whether or not maintaining direct REST API connections would be worthwhile. And the answer is, in certain cases, it probably makes sense to do that, but so far, we have not come across a compelling case where that would be the best answer. One of the other reasons to make use of the optimal Message Broker is that we are implementing traceability in the messages that are passed across the various topics, so that will allow over the course of message being generated on one topic, triggering a secondary algorithm that produces a secondary message on a different topic, or even the same topic, and on down the road, the traceability and the header information will allow someone to Be able to back up where a message was originally derived from the information that was originally caused it to be triggered to be generated. So that's one of the big reasons why we also want to make use of the Kafka message interface. But again, there are likely exceptions to Al rules. Surely, there are reasons to do so,

Unknown Speaker  38:49
like you're saying,

Speaker 4  38:50
prefer to pass a message bus, but that is

Speaker 5  38:58
certainly the preference. We also have some subsystems that are setting up topics to just be a request topic and a response topic, so you would effectively mimic a REST interface via topic or combination of topics. And that appears like it should work fine. There's no reason why it could not or will not work Fair enough.

Speaker 6  39:24
So I think it's important. I was going to teach this subject a little bit during my talk, but it's important to remember in the lab for stability is key. So if you have a product and you think REST API is the right approach, do that. It may not fall into the exact design of well res art, but this is not well resort SBA tech. So it's important to remember that there are teams that are using APIs. Basically everyone here started that. So your existing companies that started in cohort one all the way through cohort four, all of them were developing APIs. We switched to Kafka last cohort. And yes, I would agree. I think that's the preferred mechanism to transmit data. But if API works, please create an API. If you do both, sure there are companies here that will be doing both, so that they can keep their products separable from welders are but also integrate into well,

Speaker 5  40:33
we'll add to that that a lot of the companies that originally only Set up REST APIs are now transitioning over to making use of a Kafka of sub architecture, or to at least incorporate both the other questions,

Speaker 7  41:01
any differences of systems. There are requests out. Do any like you? Or is that open?

Speaker 5  41:11
Sorry, are you asking if, if there's a desire to create new topics, who should you talk to? Like,

Speaker 7  41:15
do you have to talk I've had, like, managed, or can we just, I know, sometimes Kafka is left open. So you know,

Speaker 5  41:20
it's, it's, it's restrictive. So anyone can subscribe to topics, and you can get an account by talking with Dan and the instructor team. It may take a little bit to get that set up, and it requires white listing the IPs that you're connecting from in order to produce data or to create topics, you need to get additional permissions. Producing messages will likely be tied to approval from your subsystem leads. So talk to them once you have a message that you're wanting to produce in a regular cadence, and then in terms of creating topics, that there's only a handful of folks who are able to do that, but it's a matter of seconds, right? So it's really a matter of coordinating that there are also some test topics. So even if you're not normally able to produce data to a particular subsystem, series of topics. There are test environments that you can publish to. There's just a much shorter duration, like 12 hours instead of four week. Other questions,

Speaker 2  42:37
all right. Well, thank you, Alex. We can switch over to some of you on a bulk just below. There's our slides that I sent you we can switch to there. Oh, you online?

Unknown Speaker  42:50
Got anyone from subsystem one?

Unknown Speaker  43:01
I knew there? I

Speaker 2  43:50
We're gonna have a guest phone for subsystem one. Patrick Ramsey, subsystem lead for two. We'll also brief in this one. Y'all Okay, morning,

Speaker 4  43:57
everybody. My name is Patrick Ramsey with the Aerospace Corporation. I've been involved in the tap lab for this is going to be my fifth cohort, and I am the lead for the subsystem two. But in the interim, here talking about subsystem one, this is a very interesting subsystem, because it's all about data exposure and data exploitation. There is a lot of information that is out there in terms of state information about what do we know is, what are the capabilities of adverse potential adversary satellites? What could be the capabilities of potential adversary satellites? And then, how do we aggregate that? How do we do this sort of pattern of life, pattern behavior, Expo analysis, and then, most importantly, how do we make that accessible out to every team within welders arc, so that they can use that data we're talking about, hey, this is of interest to Me as a propagation person. What is the drag area of a satellite? How would we estimate how big a satellite is? That sort of information we would be referencing back to the target model database. I have a launch site that I want to know. What are the estimates coming out of I have to ask here is basically, if you have an interesting data source that you can make available, we are creating a networked database of databases, a data store, as Tony likes to call it. I refer to it more as a data mall, because there's a lot of separate stores within and, yeah, trying to create a networked infrastructure through the tap lab for that. Hi, Cindy.

Speaker 8  45:48
Hi Patrick. Thanks. Hi. I'm Cindy from planetary systems. Ai, I'm actually on the subsystem. I didn't realize our leads weren't there. Sorry, you're you're sort of correct. The target model database is actually a threat catalog of red and blue space vehicles and objects in orbit that we are tracking. So that's what the tmdd is. That's what it stands for. And there are a number of teams that have provided information and data into the that's part populating the tmdd With this information, and the other substances. Can then pull that data to look at specific objects and vehicles and whatnot. Yes, it is all that. But more specifically, we work towards red and blue vehicles, specifically looking at that and their capabilities and payloads. So that's a brief summary that maybe I'll help you with. That is, I hope you don't mind.

Unknown Speaker  46:43
Thank you for the rescue. Are

Unknown Speaker  46:48
there any questions for Cindy before we talk about subsidy one for Patrick? Hey,

Unknown Speaker  46:57
this is the one. I actually know what's going

Speaker 4  47:01
on. So state estimation, we have a lot of sensor data coming in, and we need to exploit that into useful data products for the other teams to say, where can I look for a satellite? What is it doing up there? Where is it going to be tomorrow? So in the most boring way possible, we are catalog magnets, delightfully boring, but it's so important. I consider such as compute to be fairly foundational in the analysis and exploitation of data on on orbit. So that means that we have to run the gamut from raw observations, which are being produced by subsystem zero, all the way out into states, orbit predictions and every intermediate product that comes out of that we are interested in updating states on objects, detecting maneuvers and detecting new objects in uncorrelated Track data. So this is a particular interesting thing, because we're interested in rapid acquisition of new objects, detection of objects that may be attempting to evade our sensor networks and therefore only show up sporadically. And additionally, looking for COVID deployments, maybe even deployments hidden in like debris shedding events. So we are you know all about interrogating those little points of light that show up in your telescopes and those little returns from your radars and trying to find them tomorrow. We're part of a pipeline here. Hi, Cindy,

Unknown Speaker  48:32
you back? Okay?

Speaker 4  48:35
Yeah, doing correlation, orbit determination, ECG processing, maneuver detection and propagation, primarily. So, if you are interested in providing these sorts of tools, we will love you. And if you're interested in exploiting that sort of data, look forward to working with you.

Unknown Speaker  49:00
Questions to subsystem two.

Unknown Speaker  49:07
Thank you, Patrick, John, you online

Unknown Speaker  49:10
for SubSys. I'm here.

Unknown Speaker  49:13
Do you have slides? Or is this one that you've written

Speaker 9  49:17
to? Ooh, I had slides, but this will work as well. So this is pretty much it, but condensed, so let's do it. So yep, I'm John Dunn. I'm here the lead for c2 subsystem, and I'll use this time kind of just give a broad overview of the c2 subsystem, especially for those folks who are new to the cohort, or even those who've been around, kind of give you an idea for you know, whether you guys fit into the c2 subsystem, or if you've got data or capability that's potentially valuable. So what is the c2 subsystem? I like to classify it as for welders. Arc is supporting two broad functions, and very broad functions of that. It's the big one, and this is where most of the meat of potatoes is, is the sensor tasking and orchestration. It's really the how do I drive observations and drive data into the wilderzark system to answer questions or follow up on questions that we might have posed. And I use questions very broadly. We can get the to this the CCDM portion, but it's, you know, can I start to characterize an object, or can I collect observations on an object, either just to continue to assess if I have custody, or can assess if it's got hostile intent or other characteristics associated with it. So that's one big function of the c2 so that's them here at welders arc. The other one here is really classified as general prioritization, or object prioritization, across the subsystem. Now welders arc, there's many space domain awareness tools out there, but for us specifically, we are here to try to track red and blue assets. And with that, a subset of all objects in orbit are red and blue, and we're only interested in, even then, a subset of that. So with that, we're here to interoperate with the other subsystems, and between CCDM subsystem state estimation and hostile and your subsystem five and six attempts to create, effectively, a ranking of objects, one two and a priority across all the objects that we have to possibly track. We've got resource constraint issue when it comes to sensors. So ultimately, it comes down to we've only got so many sensors. How do we ultimately get the most observations and answer the most questions we can in the most efficient manner and targets that we can it's, it's a bit of a balancing game. And c2 is there, ultimately, to try to do that and orchestrate that in the most effective manner between the sensors and the internal components within the Wilder SARC subsystem. So those are kind of the two broad, very broad function that the c2 subsystem performs. Now for those new the the cohort, the most relevant problem statements I'll point you to are problem seven, problem eight, problem 21 and problem 44 and to reiterate those, I'm sure most people don't have those in front of you. Problem seven is specifically using orbital data and or knowledge of sensors and satellites develop a sensor search technique that maximizes the likelihood of requiring a satellite or space launch vehicle. This technique must be valid for ground or space based based EOIR and just different sensors of varying phenomenology. And problem seven and eight are very similar. I kind of combine them together right now for our purposes here, and say in your mental models. In essence, when people are looking to see if your capability aligns, it's generally I have an object up, either newly launched or just maneuvered. How can I through either an algorithm to the sensors or in terms of the c2 subsystem, determine and narrow down where this object might be, given uncertainty around its current state or past state that's now propagated forward. And how do we go and reduce that uncertainty and ultimately start getting observations again on this object and reacquire custody? That's kind of the big picture of where this these two problems statement sit or drive towards the last two problem statements from 21 and 2421 is a pretty bread and butter, simple one in terms of all the other problem statements, derive sensor models dynamically from data, this may include fob or fo, R and various characteristics related to those sensor platforms, and then update that model automatically. And you could, for those who can't already see it best to inform the tasking side of this to when we do sensor access and feasibility analysis, that problem is pretty well locked down, and it's also lower priority. I'll just kind of make a note on that one. And then the final problem here is kind of that integration between c2 and the CCDM, which is we need to develop. And this gets to kind of, kind of combining the priority of objects across CCDM subsystem state estimation and threat and your hostility assessment and subsystem six, which is develop a process to automatically nominate objects for additional removal to either a HR list, order a battle or modify the relative ranks of objects on an HR list. The idea here is we need to look at the CCDM indicators that we have, along with potentially our current assessed custody value, or the likelihood that we continue to be able to generate observations on an object and rack and stack that object in terms of priority queue. And that's the that's the overall objective of problem 24 now those are kind of the primary or most relevant objectives in problem statements, but certainly there's tie ins for c2 across the other problem statements that we've got. So near term objectives here, and I say near term, this is more eight ish months, potentially less. There's certainly more work after that. But this is all kind of in preparation for Victus Hayes, the big muscle movements that we have completed and that we're looking towards, include really locking in our tasking interface with the c2 sensors, specifically, as Alex alluded to, we're really utilizing the UDL, collect requests and responses and some of the schemas available there to interact with sensor providers and get that kind of simple but core, Fundamental feedback loop between those two subsystems running to drive ops, we moved to Kafka, or we're moving to Kafka. So we are still going to continue to use UDL for collect responses and requests for all the sensor providers out there. But given the advent of Kafka, here, we're looking at rolling in health status, and there might be other interesting opportunities between c2 and sensor providers in terms of message types that we can pass through Kafka. The the other two big items that we have left here that we're working towards is what I'm calling quote, unquote custody assessment, which is given an object's last known state and its predicted future sensor coverage and gaps. What level of confidence do I have that I can predict where that object will be and accurately task sensors against it in the future, in essence, and I've had Sean describe me as like this, I can say I've got custody. If I can go task a sensor, and it can go pick up that object in the future, as I, you know, as I believe it can. And if I can't do that, then the chances are I don't have custody. So there's, there's a few pieces to of that problem to unpack, but that's a that's one of the big pieces, and a sub piece of that is the search and reacquire bit that Dr ferlish referred to at the beginning. And that's that's kind of our big our big target for this cohort, which is given a launch and a newly introduced object, I need to quickly reacquire or task sensors around the potential launch nominal to start generating observations and get a confident orbit determination, so I can begin to track that object and move into the characterization phase, which is something that we've worked and with Catalyst space with their indicator API, and that is the final piece that we're looking at In the next few months, which is called characterization driven tasking, which is given that I've got custody of an object, I need to task out my sensors of varying phenomenology to confirm or refute certain indicators of CCDM. And the more efficiently and effectively I can do that, not only do I not only have to task less sensors, but I can more quickly drive red or blue recommendations in terms of is this hostile or not hostile? So those are the three major objectives that we've gotten the short term. And I'll just real quick, since I don't have the other side here, I'll just quickly reference you to the table that we've got in the bottom ranked. So inputs, outputs, these are more general information sets of what are of interest to the c2 subsystem, both from an input and output perspective. So I won't go through the laundry list here, but you can see that we're interested both in launch for queuing of sensors various launch related data, including POIs and nominals and detections. And then we're also interested as well in maneuver detections and other data related to on orbit assets to help drive whether I need to task sensors to within a certain area to regain custody or maintain custody, so that c2 in a nutshell, I'll leave it at

Speaker 2  1:00:15
that. Thank you. John. Questions in the room are online for John. I I

Speaker 5  1:00:26
just wanted to reiterate real quick on the SDA sensor side, my goal is to have all existing SDA sensors that have been supporting the lab to ingest collect requests and able to perform tip and queue off of them inside the coming weeks. The goal there is very, very short term to have that turned around and then to start producing collect response messages, although not mandatory, is highly desired for interfacing with c2 Those are both relatively short term goals, and then moving forward beyond that, longer term is developing the necessary infrastructure to support search and require using common interfaces in UDL, which at the moment is likely to include making use of sparsely populated manifolds. Wanted to reiterate that we have very close interactions with John and vitos. Thanks,

Speaker 2  1:01:35
Ellis, there's no questions we can go on to substance support Fernando. He has his own slides as well. I

Unknown Speaker  1:01:51
supposed to push

Unknown Speaker  1:01:54
Yes.

Speaker 10  1:01:56
Hello guys. My name is Fernando unit, and I'm with Catalyst Vegas technologies. We are the leads of subsystem four and been participants of the FDA tab lab since the first cohort. Makes a job for introducing you guys to CCDM, which stands for camouflage, concealment, deception and maneuver. And the whole goal of subsystem four is to really help us avoid operational surprise. This is what the big goal in the tap lab is, and this is what we're here to do. We want to evaluate objects for CCDM, interrogate them with observational data, whether it be a radar, electronic go and such, to provide us indicators. With those indicators, we can then aggregate that into a database and then ultimately provide objects of interest list that we can pass on to subsystem three or other subsystems within the other sargs and all these indicators live off of individual models. I think the great thing about subsist four is that we can rely on individual models to develop the whole database, right? We don't need one single model to be able to provide the data that we need. For example, if one of the catalyst models goes down, a model from dignity or style hanky can, if they have that specific indicator, they can provide that source of data for us. And so it's kind of like a very dynamic database that everybody can use. So to all the new members within the tap lab, we do have a list of indicators that we have been attacking with all the cohort members available for you guys to look at if you are interested in CCDM evaluation, we do work with each individual company to try to tackle a specific subset of problems within problem 16 of the tap lab. So feel free to reach out for me for that we have an REST API that we use to interact with others, but we've also developed on the message bus, and had been onboarding others to get onto that as well. Really, that's major, the major aspects of substance, of force, getting those indicators together to be able to provide to other people. Kind of our future work for now is, you know, continue integrating others into the subsystem, helping indicators help them integrate the message for us, and then we are in works of integrating a prove and improved framework for hypothesis testing based on a probabilistic classification. Any questions?

Speaker 2  1:04:49
Thank you, Fernando, appreciate that. We'll go straight on to subsidism Five Jubilee. You are online. Your slides are up.

Unknown Speaker  1:05:01
Yes, sir, these are not my slides. I

Speaker 1  1:05:13
think those are Dan's, Dan relic slides, if I'm not mistaken

Unknown Speaker  1:05:19
Dan by Organic. Okay.

Unknown Speaker  1:05:26
I was thinking, I'm not this funny. I

Speaker 11  1:05:42
Yes. Thank you. Good morning, everybody. I am Julie Prasad Al and I'm from GTC analytics and supporting the subsystem five work teams within subsystem five. Subsystem five, small possibility monitoring. And we're doing multiple things in here. From all the green blocks, you see there are inputs coming in to subsist by different external sequencers, different databases within the lab and external for the lab and outputs from other subsystems are also coming into algorithms within subsystem five to provide various outputs, which include predicting launch windows, detecting those launches, generating launch nominals, and then on orbit, West and as circling agents own predictions. And then is there hostility related to that, basically intent assessment of those detections, whether it's launch or West predictions, and then also re entry predictions we expect some objects or likely to reenter, what objects, what locations on the earth might they go and impact? It's the kind of work that we're going doing in subsystem five. And we can go a little bit more deeper in the next points, next slide, please. So here, I just want to show you what are the different capabilities that are currently being worked on, and give you kind of like a flow of how these capabilities send messages and trigger other algorithms to work. And maybe you're working on algorithms that are complimentary to what's being done, we also look for some dependency in capabilities. So I'd be very happy to answer any questions also. So like I said, launch product detection, taking in external data, such as like social media, like satellite imagery, even ground cameras, to get the exact type of launch, if that is available, publicly available information on launch launch, as we gather all of those information and send them to kahwabus to say, hey, we know that there's a launch in the the next few days that we might want to monitor, depending on what information is available, does it pose any threat to any of the satellites in space? Kind of analysis that can be done with launch prep detection, type of messages we can get. And then we also have persistent seismic and in person monitoring we are working on. We have satellite imagery based launch detection, ground camera based launch detection. We look at different satellite imagery plans to do these detections if there's no launch prep message from publicly available information, all we get is a launch detection alert. Then maybe somebody is trying to launch without publicly disclosing the launch, and it might be a hostile event that we want to tax defensers to. Make it secret. Team will get this message and task sensors to get images of that vehicle and the satellites that it releases in space. That's the mission. Next, Next slide, please. We also do launch terminals, and then do have some algorithms that take the launch terminals and then even launch windows in the launch prediction stage and figure out what are the satellites in space, or groups of satellites in space that might be at risk if a launch happens at a certain time and a certain azimuth, so that we have that information ready to task satellites to do evasive manures move from that location, to reduce the risk and so on. And that would be in collaboration with SS six, which is doing response recommendation based on the hostile intent analysis that SS five does so here, this is the launch processing stage, where, based on the launch detections, we generate launch terminals. We look at any orbital threats, where are these vehicles can go, and what satellites might be released and in which orbit kind of analysis. There's also an analysis where, when the launch happens, we can get multiple images of the launch in the first couple of minutes, and we try to predict the ascent trajectory of the vehicle itself and make sure that it matches with what is available from publicly available information to be the launch mission. Is it going in the right direction, right altitude, and what's the threat from that if it deviates from that kind of analysis is also being done. Next slide, please. This all the blocks in the middle here have to do with permanent Engagement Zone. Type of predictions we have electro optical as well as predictions, which includes sensors in space, sensors on the ground, blue satellites or moving around. Kevin Brown sensor take images of that our asset, and when are those times we can predict them? Some algorithms run multiple times each day and predict for the next 24, hours, eight hours, and they can be used to assist people along with other information. We have arc jamming predictions. We have kinetic kill vehicle type of analysis. And on the left, we show all the inputs that are coming into these algorithms. On the right, we show where the outputs even, pattern of life violations can be detected or being detected through analysis here as well. Next slide, please. And finally, when these types of bus pass are predicted, when there's a launch predicted, using all the available information, we try to assess, is there intent to do any harm or or is there no harmful intent? This can be done at various levels, taking different types of information, and this is very relevant for SS six, so that they can respond or recommend the appropriate responses based on this or you get information. So overall, SS five, we like assess detect events as well as assess hostility of those events, from launch all the way to in space operations, as well as re entry events as well and their hostility. Are there any if you have any capability that you think fits in well, complements or provides, like additional methods or different methods to deliver the same capabilities that could be that would add redundancy. I'd be very happy to talk with you and answer any questions to figure out where you fit into the chain decomposition. I I have one more slide. This just shows how messages are are processed, in a way, on the Kafka bus. What capabilities send? What messages? When does a launch start? When do we say a launch has ended? You have the launch prediction on the top left modules that provide a launch prediction alert, and that's taken by launch window assessment algorithms. We'd say, hey, the vehicle launches at a certain time. What are the types of what are the groups of satellites that are risk? We can even further go and like, assess like, what would the trajectory of the vehicle be if it launches at a certain, certain time? And then, like I said, then if we have that, then we task satellites to get images for launch detection, while there are certain persistent methods are also continuously detecting for launches that we don't know, for publicly available information. This is just for the launch event. How do we go from launch prediction, launch detection, launch processing to response recommendation, and we are developing these for also other events, like maneuver, proximity and so on and so forth. That would just be helpful to see where you fit into this chain. I think that's the last slide.

Speaker 2  1:15:51
Thank you. Julie. Questions for Julie. For anyone, we will move on to our last subsystem, subsystem six, Max going. I mind.

Speaker 12  1:16:04
Yes, I'm online, so I'm Max brown with data fusion and neural networks. I am one of the subsystem leads for subsystem six, the response recommendation subsystem. My colleague is their local in Colorado Springs. He has traveled last week and this week, but he's he loves being in person in the tap lab, so look, look out for him to talk to him when he's back in the tap lab, although I believe he'll be back this next week. But to give an overview of subsystem six, we in subsystem six are in charge of generating a response recommendation. After all, this data from the other subsystems has been generated and processing has been worked on it, so we ingest in subsystem six target information, weapon and payload Engagement Zone information. We also take into consideration the standing rules of engagement, and then we start to get into the broader picture of where welders arc as a battle management system would be used as we consider the state of hostility as well as administrative constraints for the user of the battle management system, and using that information, we output a prioritized list of courses of action with their associated tactics, techniques and protocols that the user of this system could then use to select a course of action to take when an event arises inside the wilderzark system. So I find it most helpful to kind of explain giving a brief example of what that would look like. So for example, after processing has happened in subsystem five, we may get past a payload engagement zone that is telling us that a red satellite is coming to take a picture of a blue satellite. The user of the battle management system is then going to have some options. We would generate a prioritized list of courses of action that they can take. They could either take out of the different choices there's, for example, the user could choose to assess the situation more which would assign more tasking, possibly to different sensors, if we integrate with c2 and that would that would then more observations, hopefully on the event that's coming up, or the user can select to a day or do Something to mitigate the effects of this event that's coming up. And we would do this for any amount of events, usually it maps to subsystem five, a payload or weapon Engagement Zone. So for example, a different scenario could be maybe a red satellite is coming in to smash our blue satellite with a kinetic kill vehicle attack, and there would be a different set of recommendations we would offer and also present information to the user of the system to be able to respond to that threat with the information they need to make a good decision. Some of the things I'll kind of talk about is there are different we work very closely with subsystem five, Jubilee and Jesse. And if you are a company in subsystem five providing payload or weapon engagement zones. We work very closely with you, and as well, we're finding out there's some opportunities to do work kind of in between subsystem five and subsystem six, with whether that's hostility intent or somehow filtering the data that's going to come into subsystem six. So we can show the user of the battle management Management System, or welders arc the important events that they need to see at a specific time. So if you have any questions, please feel free to reach out to me on rocket chat. I'm Max Brown, or reach out to Chris Shan and you can get my email from someone if needed. And additionally, we have subsystem six weekly meeting on Tuesdays at 11am MST time. So please feel free to hop into any of those meetings. Those are a half hour, and you can kind of see what's going on in subsystem six and find out if there's any opportunity for your company to contribute there. That's it for me, unless there's any questions. Thank you.

Speaker 2  1:21:12
Max. Any questions for Max from online or in the room? Awesome. Thanks. So that was an overview. While the dark, it's a lot of information, I know, even for those of us who have seen it, I still get lost in it. Sometimes. There's a lot to it, but you can kind of see the full capability span, right? How do we go from detecting launches, processing all the data, state estimations, moving through everything, to ultimately co host, which are course of action recommendations for commanders to act on? And again, we're looking for where you all plug in and fit into those. But I think now would probably be the most appropriate time because take a 10 minute break. So we're gonna go ahead. It's about 1023 goal. We'll start back up at 1035 if you all want to be back, appreciate it.


Transcribed by https://otter.ai